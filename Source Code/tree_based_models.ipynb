{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feature_vectors.csv')\n",
    "x = df.values.tolist()\n",
    "# convert each element from string to list\n",
    "X = []\n",
    "for i in range(len(x)):\n",
    "    Z = []\n",
    "    for j in range(len(x[i])):\n",
    "        # if x[i][j] is string\n",
    "        if isinstance(x[i][j], str):\n",
    "            p = x[i][j].strip('][').split(', ')\n",
    "            Z.append(p)\n",
    "            # convert each element from string to int\n",
    "            for k in range(len(p)):\n",
    "                p[k] = float(p[k])\n",
    "        else :\n",
    "            break\n",
    "    X.append(Z)\n",
    "\n",
    "df2 = pd.read_csv('manual_markings.csv')\n",
    "y = df2.values.tolist()\n",
    "# convert each element from string to list\n",
    "Y = []\n",
    "for i in range(len(y)):\n",
    "    Z = []\n",
    "    for j in range(len(y[i])):\n",
    "        # if x[i][j] is 0 or 1\n",
    "        if y[i][j] == 0 or y[i][j] == 1:\n",
    "            Z.append(int(y[i][j]))\n",
    "        else: break\n",
    "    Y.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = [item for sublist in X_train for item in sublist]\n",
    "Y_train = [item for sublist in Y_train for item in sublist]\n",
    "X_test = [item for sublist in X_test for item in sublist]\n",
    "Y_test = [item for sublist in Y_test for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = np.array(X_train)\n",
    "X_train_arr[np.isnan(X_train_arr)] = 0\n",
    "\n",
    "Y_train_arr = np.array(Y_train)\n",
    "Y_train_arr[np.isnan(Y_train_arr)] = 0\n",
    "\n",
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "\n",
    "# Resample the dataset using SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_arr, Y_train_arr)\n",
    "\n",
    "X_train = X_resampled.tolist()\n",
    "Y_train = y_resampled.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier()\n",
    "model1.fit(X_train, Y_train)\n",
    "\n",
    "# save the model\n",
    "pickle.dump(model1, open('decision_tree.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AdaBoostClassifier()\n",
    "model2.fit(X_train, Y_train)\n",
    "\n",
    "# save the model\n",
    "pickle.dump(model2, open('ada_boost.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier()\n",
    "model3.fit(X_train, Y_train)\n",
    "\n",
    "# save the model\n",
    "pickle.dump(model3, open('random_forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635135135135135\n",
      "[[85 24]\n",
      " [11 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       109\n",
      "           1       0.54      0.72      0.62        39\n",
      "\n",
      "    accuracy                           0.76       148\n",
      "   macro avg       0.71      0.75      0.72       148\n",
      "weighted avg       0.79      0.76      0.77       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('decision_tree.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777027027027027\n",
      "[[91 18]\n",
      " [15 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       109\n",
      "           1       0.57      0.62      0.59        39\n",
      "\n",
      "    accuracy                           0.78       148\n",
      "   macro avg       0.71      0.73      0.72       148\n",
      "weighted avg       0.78      0.78      0.78       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('ada_boost.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108108108108109\n",
      "[[98 11]\n",
      " [17 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       109\n",
      "           1       0.67      0.56      0.61        39\n",
      "\n",
      "    accuracy                           0.81       148\n",
      "   macro avg       0.76      0.73      0.74       148\n",
      "weighted avg       0.80      0.81      0.81       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('random_forest.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('indian_accent_feature_vectors.csv')\n",
    "x_test = df.values.tolist()\n",
    "# convert each element from string to list\n",
    "X_test = []\n",
    "for i in range(len(x_test)):\n",
    "    Z = []\n",
    "    for j in range(len(x_test[i])):\n",
    "        # if x_test[i][j] is string\n",
    "        if isinstance(x_test[i][j], str):\n",
    "            p = x_test[i][j].strip('][').split(', ')\n",
    "            Z.append(p)\n",
    "            # convert each element from string to int\n",
    "            for k in range(len(p)):\n",
    "                p[k] = float(p[k])\n",
    "        else :\n",
    "            break\n",
    "    X_test.append(Z)\n",
    "\n",
    "df2 = pd.read_csv('word_markings_indian_accent.csv')\n",
    "y_test = df2.values.tolist()\n",
    "# convert each element from string to list\n",
    "Y_test = []\n",
    "for i in range(len(y_test)):\n",
    "    Z = []\n",
    "    for j in range(len(y_test[i])):\n",
    "        # if x[i][j] is 0 or 1\n",
    "        if y_test[i][j] == 0 or y_test[i][j] == 1:\n",
    "            Z.append(int(y_test[i][j]))\n",
    "        else: break\n",
    "    Y_test.append(Z)\n",
    "\n",
    "X_test = [item for sublist in X_test for item in sublist]\n",
    "Y_test = [item for sublist in Y_test for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance report of the model is :\n",
      "              Precision    Recall  F1-Score   Support\n",
      "\n",
      "            0      0.75      0.60      0.67       225\n",
      "            1      0.43      0.59      0.49       112\n",
      "\n",
      "     Accuracy                          0.60       337\n",
      "    Macro_avg      0.59      0.60      0.58       337\n",
      " Weighted_avg      0.64      0.60      0.61       337\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('decision_tree.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance report of the model is :\n",
      "              Precision    Recall  F1-Score   Support\n",
      "\n",
      "            0      0.78      0.68      0.73       225\n",
      "            1      0.50      0.63      0.55       113\n",
      "\n",
      "     Accuracy                          0.66       338\n",
      "    Macro_avg      0.64      0.65      0.64       338\n",
      " Weighted_avg      0.69      0.66      0.67       338\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('ada_boost.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance report of the model is :\n",
      "              Precision    Recall  F1-Score   Support\n",
      "\n",
      "            0      0.77      0.73      0.75       225\n",
      "            1      0.52      0.58      0.55       113\n",
      "\n",
      "     Accuracy                          0.68       338\n",
      "    Macro_avg      0.65      0.65      0.65       338\n",
      " Weighted_avg      0.69      0.68      0.68       338\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('random_forest.pkl', 'rb'))\n",
    "\n",
    "X_test_arr = np.array(X_test)\n",
    "X_test_arr[np.isnan(X_test_arr)] = 0\n",
    "X_test = X_test_arr.tolist()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
