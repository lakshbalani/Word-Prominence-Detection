{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation for Improved Deep Embedded Clustering as described in paper:\n",
    "\n",
    "        Xifeng Guo, Long Gao, Xinwang Liu, Jianping Yin. Improved Deep Embedded Clustering with Local Structure\n",
    "        Preservation. IJCAI 2017.\n",
    "\n",
    "Usage:\n",
    "    Weights of Pretrained autoencoder for mnist are in './ae_weights/mnist_ae_weights.h5':\n",
    "        python IDEC.py mnist --ae_weights ./ae_weights/mnist_ae_weights.h5\n",
    "    for USPS and REUTERSIDF10K datasets\n",
    "        python IDEC.py usps --update_interval 30 --ae_weights ./ae_weights/usps_ae_weights.h5\n",
    "        python IDEC.py reutersidf10k --n_clusters 4 --update_interval 3 --ae_weights ./ae_weights/reutersidf10k_ae_weights.h5\n",
    "\n",
    "Author:\n",
    "    Xifeng Guo. 2017.4.30\n",
    "\"\"\"\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "from DEC import cluster_acc, ClusteringLayer, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDEC(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 n_clusters=10,\n",
    "                 alpha=1.0,\n",
    "                 batch_size=256):\n",
    "\n",
    "        super(IDEC, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.input_dim = dims[0]\n",
    "        self.n_stacks = len(self.dims) - 1\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.autoencoder = autoencoder(self.dims)\n",
    "\n",
    "    def initialize_model(self, ae_weights=None, gamma=0.1, optimizer='adam'):\n",
    "        if ae_weights is not None:\n",
    "            self.autoencoder.load_weights(ae_weights)\n",
    "            print ('Pretrained AE weights are loaded successfully.')\n",
    "        else:\n",
    "            print ('ae_weights must be given. E.g.')\n",
    "            print ('    python IDEC.py mnist --ae_weights weights.h5')\n",
    "            exit()\n",
    "\n",
    "        hidden = self.autoencoder.get_layer(name='encoder_%d' % (self.n_stacks - 1)).output\n",
    "        self.encoder = Model(inputs=self.autoencoder.input, outputs=hidden)\n",
    "\n",
    "        # prepare IDEC model\n",
    "        clustering_layer = ClusteringLayer(self.n_clusters, name='clustering')(hidden)\n",
    "        self.model = Model(inputs=self.autoencoder.input,\n",
    "                           outputs=[clustering_layer, self.autoencoder.output])\n",
    "        self.model.compile(loss={'clustering': 'kld', 'decoder_0': 'mse'},\n",
    "                           loss_weights=[gamma, 1],\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "    def load_weights(self, weights_path):  # load weights of IDEC model\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def extract_feature(self, x):  # extract features from before clustering layer\n",
    "        encoder = Model(self.model.input, self.model.get_layer('encoder_%d' % (self.n_stacks - 1)).output)\n",
    "        return encoder.predict(x)\n",
    "\n",
    "    def predict_clusters(self, x):  # predict cluster labels using the output of clustering layer\n",
    "        q, _ = self.model.predict(x, verbose=0)\n",
    "        return q.argmax(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def target_distribution(q):  # target distribution P which enhances the discrimination of soft label Q\n",
    "        weight = q ** 2 / q.sum(0)\n",
    "        return (weight.T / weight.sum(1)).T\n",
    "\n",
    "    def clustering(self, x, y=None,\n",
    "                   tol=1e-3,\n",
    "                   update_interval=140,\n",
    "                   maxiter=2e4,\n",
    "                   save_dir='./results/idec'):\n",
    "\n",
    "        print ('Update interval', update_interval)\n",
    "        save_interval = x.shape[0] / self.batch_size * 5  # 5 epochs\n",
    "        print ('Save interval', save_interval)\n",
    "\n",
    "        # initialize cluster centers using k-means\n",
    "        print ('Initializing cluster centers with k-means.')\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        y_pred = kmeans.fit_predict(self.encoder.predict(x))\n",
    "        y_pred_last = y_pred\n",
    "        self.model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "\n",
    "\n",
    "        loss = [0, 0, 0]\n",
    "        index = 0\n",
    "        for ite in range(int(maxiter)):\n",
    "            if ite % update_interval == 0:\n",
    "                q, _ = self.model.predict(x, verbose=0)\n",
    "                p = self.target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "                # evaluate the clustering performance\n",
    "                y_pred = q.argmax(1)\n",
    "                delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "                y_pred_last = y_pred\n",
    "                if y is not None:\n",
    "                    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "                    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "                    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "                    loss = np.round(loss, 5)\n",
    "                    logdict = dict(iter=ite, acc=acc, nmi=nmi, ari=ari, L=loss[0], Lc=loss[1], Lr=loss[2])\n",
    "                    print ('Iter', ite, ': Acc', acc, ', nmi', nmi, ', ari', ari, '; loss=', loss)\n",
    "\n",
    "                # check stop criterion\n",
    "                if ite > 0 and delta_label < tol:\n",
    "                    print ('delta_label ', delta_label, '< tol ', tol)\n",
    "                    print ('Reached tolerance threshold. Stopping training.')\n",
    "                    break\n",
    "\n",
    "            # train on batch\n",
    "            if (index + 1) * self.batch_size > x.shape[0]:\n",
    "                loss = self.model.train_on_batch(x=x[index * self.batch_size::],\n",
    "                                                 y=[p[index * self.batch_size::], x[index * self.batch_size::]])\n",
    "                index = 0\n",
    "            else:\n",
    "                loss = self.model.train_on_batch(x=x[index * self.batch_size:(index + 1) * self.batch_size],\n",
    "                                                 y=[p[index * self.batch_size:(index + 1) * self.batch_size],\n",
    "                                                    x[index * self.batch_size:(index + 1) * self.batch_size]])\n",
    "                index += 1\n",
    "\n",
    "            # save intermediate model\n",
    "            if ite % save_interval == 0:\n",
    "                # save IDEC model checkpoints\n",
    "                print ('saving model to:', save_dir + '/IDEC_model_' + str(ite) + '.h5')\n",
    "                self.model.save_weights(save_dir + '/IDEC_model_' + str(ite) + '.h5')\n",
    "\n",
    "            ite += 1\n",
    "\n",
    "        # save the trained model\n",
    "        print ('saving model to:', save_dir + '/IDEC_model_final.h5')\n",
    "        self.model.save_weights(save_dir + '/IDEC_model_final.h5')\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/feature_vectors.csv')\n",
    "\n",
    "x = df.values.tolist()\n",
    "# convert each element from string to list\n",
    "X = []\n",
    "for i in range(len(x)):\n",
    "    Z = []\n",
    "    for j in range(len(x[i])):\n",
    "        # if x[i][j] is string\n",
    "        if isinstance(x[i][j], str):\n",
    "            p = x[i][j].strip('][').split(', ')\n",
    "            Z.append(p)\n",
    "            # convert each element from string to int\n",
    "            for k in range(len(p)):\n",
    "                p[k] = float(p[k])\n",
    "        else :\n",
    "            break\n",
    "    X.append(Z)\n",
    "X = [item for sublist in X for item in sublist]\n",
    "\n",
    "df2 = pd.read_csv('/content/drive/MyDrive/manual_markings.csv')\n",
    "y = df2.values.tolist()\n",
    "# convert each element from string to list\n",
    "Y = []\n",
    "for i in range(len(y)):\n",
    "    Z = []\n",
    "    for j in range(len(y[i])):\n",
    "        # if x[i][j] is 0 or 1\n",
    "        if y[i][j] == 0 or y[i][j] == 1:\n",
    "            Z.append(int(y[i][j]))\n",
    "        else: break\n",
    "    Y.append(Z)\n",
    "Y = [item for sublist in Y for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X)\n",
    "y = np.array(Y)\n",
    "\n",
    "x[np.isnan(x)] = 0\n",
    "y[np.isnan(y)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=0.1, momentum=0.99)\n",
    "\n",
    "idec = IDEC(dims=[x.shape[-1], 500, 500, 2000, 10], n_clusters=2, batch_size=256)\n",
    "idec.initialize_model(ae_weights=args.ae_weights, gamma=0.1, optimizer=optimizer)\n",
    "plot_model(idec.model, to_file='idec_model.png', show_shapes=True)\n",
    "idec.model.summary()\n",
    "\n",
    "# begin clustering, time not include pretraining part.\n",
    "t0 = time()\n",
    "y_pred = idec.clustering(x, y=y, tol=0.001, maxiter=2e4,\n",
    "                            update_interval=140, save_dir='results/idec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('acc:', cluster_acc(y, y_pred))\n",
    "print ('clustering time: ', (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/indian_accent_feature_vectors.csv')\n",
    "\n",
    "x_indian = df.values.tolist()\n",
    "# convert each element from string to list\n",
    "X_indian = []\n",
    "for i in range(len(x_indian)):\n",
    "    Z = []\n",
    "    for j in range(len(x_indian[i])):\n",
    "        # if x_indian[i][j] is string\n",
    "        if isinstance(x_indian[i][j], str):\n",
    "            p = x_indian[i][j].strip('][').split(', ')\n",
    "            Z.append(p)\n",
    "            # convert each element from string to int\n",
    "            for k in range(len(p)):\n",
    "                p[k] = float(p[k])\n",
    "        else :\n",
    "            break\n",
    "    X_indian.append(Z)\n",
    "X_indian = [item for sublist in X_indian for item in sublist]\n",
    "\n",
    "df2 = pd.read_csv('/content/drive/MyDrive/word_markings_indian_accent.csv')\n",
    "y_indian = df2.values.tolist()\n",
    "# convert each element from string to list\n",
    "Y_indian = []\n",
    "for i in range(len(y_indian)):\n",
    "    Z = []\n",
    "    for j in range(len(y_indian[i])):\n",
    "        # if x[i][j] is 0 or 1\n",
    "        if y_indian[i][j] == 0 or y_indian[i][j] == 1:\n",
    "            Z.append(int(y_indian[i][j]))\n",
    "        else: break\n",
    "    Y_indian.append(Z)\n",
    "Y_indian = [item for sublist in Y_indian for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_indian = np.array(X_indian)\n",
    "y_indian = np.array(Y_indian)\n",
    "\n",
    "x_indian[np.isnan(x_indian)] = 0\n",
    "y_indian[np.isnan(y_indian)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = idec.clustering(x_indian, y=y_indian, tol=0.001, maxiter=2e4,\n",
    "                            update_interval=140, save_dir='results/idec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('acc:', cluster_acc(y_indian, y_pred))\n",
    "print ('clustering time: ', (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
